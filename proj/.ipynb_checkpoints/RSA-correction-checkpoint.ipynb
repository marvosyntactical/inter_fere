{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Disagreements and Corrections using RSA\n",
    "\n",
    "---\n",
    "\n",
    "    <world knowledge> \"ยง 14-309.8.  Limit on sessions. The number of sessions of bingo conducted or sponsored by an exempt organization shall be limited to two sessions per week and such sessions must not exceed a period of five hours each per session.\" [US NC legislation](https://www.ncleg.net/EnactedLegislation/Statutes/HTML/ByArticle/Chapter_14/Article_37.html)\n",
    "    \n",
    "    <prosecution> \"The defendant played at the bingo event for 7 hours straight.\"\n",
    "    <defense> \"At the mayfair.\"\n",
    "\n",
    "---\n",
    "This notebook is supposed to be a 1:1 adaptation of the [RSA-Hyperbole Pyro Example](http://pyro.ai/examples/RSA-hyperbole.html)\n",
    "\n",
    "It is also meant to serve as a functional (as opposed to object oriented) but otherwise identical implementation as the one in comp_implt.py\n",
    "\n",
    "---\n",
    "\n",
    "Correcting a specific detail of what someone said is a common use of language possibly requiring logical inference during interpretation. I extend the RSA Model as used in [the Pyro Example](http://pyro.ai/examples/RSA-hyperbole.html) to include a logical theorem prover and allow non-literal probabilistic interpretation of corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first some imports\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)  # double precision for numerical stability\n",
    "\n",
    "import collections\n",
    "import argparse\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "from search_inference import factor, memoize\n",
    "from phrasal import *\n",
    "from helpers import *\n",
    "rpc = wrapped_rpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domain for this example will be beliefs consisting of beliefs in first order logic form. More specifically, we will use a Neo-Davidsonian Event representation, so the event\n",
    "\n",
    "    The chicken crossed the road at an intersection.\n",
    "is normalized to:\n",
    "\n",
    "    exists e. cross(e, chicken, road) & agn(e, chicken) & pat(e, road) & loc(e, intersection)\n",
    "    \n",
    " \n",
    "This representation lends itself both to logical inference about meaning and is compositionally built up so, associated attributes can be added together.\n",
    "The implementation comes in the form a phrase class that provides an elementary cost attribute and builds up phrases incrementally from constituents. \n",
    "Priors here could be adapted from experimental data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, we are in court after Brutus murdered Caesar; two parties have different beliefs about how the event went down, one side first makes a statement how the event went down and then the other side interrupts (or decides not to). To avoid confusion it should be emphasized that the first person is the _Listener_ and the second person is the _Speaker_ as the Speech Act in focus is the correction.\n",
    "\n",
    "\n",
    "A bit of prior setup is needed for this before we can turn to the RSA model. The world knowledge is provided in a list of FOL expressions. $k_{1-4}$ are specific conditions for punishment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "expr = nltk.sem.Expression.fromstring\n",
    "\n",
    "k1 = expr(\"all x.((exists e.(kill(e,x,y) & in(e,rome))) -> should_hang(x))\")#ki    lling in forum very illegal\n",
    "k2 = expr(\"all x.((exists e.(kill(e,x,y))) -> mean(x))\")\n",
    "k3 = expr(\"all x.((exists e.(agn(e,x) & ins(e,knife))) -> should_be_lashed(x))\"    )#using knife is slightly bad\n",
    "k4 = expr(\"all x.((exists e.(loc(e,rubicon) & ins(e,paddle))) -> great(x))\")#us    ing paddle at rubicon is awesome\n",
    "\n",
    "f1 = expr(\"all e.(loc(e,forum) -> in(e, rome))\")\n",
    "f2 = expr(\"all e.(loc(e,rubicon) -> -in(e, rome))\")\n",
    "f3 = expr(\"all e.(stab(e,x,y) -> kill(e,x,y))\")\n",
    "\n",
    "swk = [k1,k2,k3,k4,f1,f2,f3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shared world knowledge (swk) is shared in the sense that each of the two interlocutors \n",
    "1. knows these facts\n",
    "2. knows the other knows them  \n",
    "  \n",
    "  \n",
    "the listener furthermore also  \n",
    "3. knows the speaker knows the listener knows them\n",
    "\n",
    "In contrast, the following beliefs are specifically pertaining to the discussed event and may differ between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from court import *\n",
    "\n",
    "beliefs = [\n",
    "         phrase([brutus, stab, caesar, forum, knife]),#prosecution belief\n",
    "         phrase([brutus, stab, caesar, forum]),\n",
    "         phrase([brutus, stab, caesar, knife]),\n",
    "         phrase([brutus, stab, caesar, forum, knife]),\n",
    "         phrase([brutus, stab, caesar, forum, sword]),\n",
    "         phrase([brutus, stab, caesar, forum, knife]),\n",
    "         phrase([brutus, stab, caesar, rubicon, sword]), \n",
    "         phrase([brutus, stab, caesar, rubicon]), \n",
    "         phrase([brutus, stab, caesar, sword]), \n",
    "         phrase([brutus, stab, caesar, sword, rubicon]),#defense belief\n",
    "         phrase([brutus, stab, caesar, rubicon, knife]), \n",
    "         phrase([brutus, stab, caesar, rubicon, sword]), \n",
    "         phrase([caesar_ag, stab, brutus_pat, forum, knife]),\n",
    "         phrase([brutus, stab, caesar, rubicon, knife, fun]),\n",
    "         phrase([brutus, stab, caesar, rubicon, sword, others, fun]),\n",
    "         phrase([brutus, row, boat, rubicon, paddle]),\n",
    "         phrase([someone_else, stab, caesar, rubicon, knife])\n",
    "      ]\n",
    "\n",
    "def belief_prior(B): #over list\n",
    "    ix = pyro.sample(\"belief\", dist.Categorical(probs=torch.ones(len(B))/len(B)))\n",
    "    return B[ix]\n",
    "\n",
    "# change at will: \n",
    "listener_belief = beliefs[0]\n",
    "speaker_belief = beliefs[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the $k_{1-4}$ which were introduced above; these are the respective conditions for the questions under discussion (QUDs) discussed by our prosecution and defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quds = {\n",
    "        \"hang\": expr(\"should_hang(brutus)\"),\n",
    "        \"mean\": expr(\"mean(brutus)\"),\n",
    "        \"lashed\": expr(\"should_be_lashed(brutus)\"),\n",
    "        \"great\": expr(\"great(brutus)\"),\n",
    "}\n",
    "\n",
    "def qud_prior(quds): #over dict\n",
    "    keys = list(quds.keys())\n",
    "    ix = pyro.sample(\"qud\", dist.Categorical(probs=torch.ones(len(keys))/len(ke    ys)))\n",
    "    qud = keys[ix.item()]\n",
    "    return qud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The RSA Literal Listener\n",
    "\n",
    "We can now turn to the literal listener ($L0$), which begins the chain of inference in the RSA model. $L0$ replaces the utterance in the listener belief according to the role the replacement has, then runs logical inference and finally produces a distribution over _beliefs_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Marginal\n",
    "def L0(correction):\n",
    "\n",
    "    interjector_belief=belief_prior(beliefs) #state_prior() in RSAhyperb\n",
    "    replacement = self.belief.replace_constituents_in_utt(correction)\n",
    "    if not type(correction) == NULL_Utt:\n",
    "        added_expr = replacement\n",
    "    else:\n",
    "        added_expr = listener_belief\n",
    "    evaluation = rpc(goal=interjector_belief.L(), assumptions=self.swk+[added_expr.L()]).prove()\n",
    "\n",
    "    factor(\"literal meaning\", 0. if evaluation else float(\"-inf\"))\n",
    "    \n",
    "    return interjector_belief\n",
    "\n",
    "correction = phrase([rubicon])   \n",
    "\n",
    "l0_dist = L0(correction)\n",
    "plot_dist(l0_dist, output=\"show\", addinfo=\"l0 interpretation of \"+str(correction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows the literal listeners interpretation of t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a version of the RSA speaker that only produces *relevant* information for the literal listener. We define relevance with respect to a Question Under Discussion (QUD) -- this can be thought of as defining the speaker's current attention or topic.\n",
    "\n",
    "The speaker is defined mathematically by:\n",
    "\n",
    "$$P_S(u|s,q) \\propto \\left[ \\sum_{w'} \\delta_{q(w')=q(w)} P_\\text{Lit}(w'|u) p(u) \\right]^\\alpha $$\n",
    "\n",
    "To implement this as a probabilistic program, we start with a helper function `project`, which takes a distribution over some (discrete) domain and a function `qud` on this domain. It creates the push-forward distribution, using `Marginal` (as a Python decorator). The speaker's relevant information is then simply information about the state in this projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Marginal\n",
    "def project(dist,qud):\n",
    "    v = pyro.sample(\"proj\",dist)\n",
    "    return qud_fns[qud](v)\n",
    "\n",
    "@Marginal\n",
    "def literal_listener(utterance):\n",
    "    state=state_prior()\n",
    "    factor(\"literal_meaning\", 0. if meaning(utterance, state.price) else -999999.)\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "@Marginal\n",
    "def speaker(state, qud):\n",
    "    alpha = 1.\n",
    "    qudValue = qud_fns[qud](state)\n",
    "    with poutine.scale(scale=torch.tensor(alpha)):\n",
    "        utterance = utterance_prior()\n",
    "        literal_marginal = literal_listener(utterance)\n",
    "        projected_literal = project(literal_marginal, qud)\n",
    "        pyro.sample(\"listener\", projected_literal, obs=qudValue)\n",
    "    return utterance\n",
    "\n",
    "@Marginal\n",
    "def pragmatic_listener(utterance):\n",
    "    state = state_prior()\n",
    "    qud = qud_prior()\n",
    "    speaker_marginal = speaker(state, qud)\n",
    "    pyro.sample(\"speaker\", speaker_marginal, obs=utterance)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible QUDs capture that the speaker may be attending to the price, her affect, or some combination of these. We assume a uniform QUD prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the utterance meanings (standard number word denotations: \"N\" means exactly $N$) and a uniform utterance prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterance_prior():\n",
    "    utterances = [50, 51, 500, 501, 1000, 1001, 5000, 5001, 10000, 10001]\n",
    "    ix = pyro.sample(\"utterance\", dist.Categorical(probs=torch.ones(len(utterances)) / len(utterances)))\n",
    "    return utterances[ix]\n",
    "\n",
    "def meaning(utterance, price):\n",
    "    return utterance == price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's see what number term this speaker will say to express different states and QUDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silly plotting helper:\n",
    "\n",
    "\n",
    "# plot_dist( speaker(State(price=50, arousal=False), \"arousal\") )\n",
    "# plot_dist( speaker(State(price=50, arousal=True), \"price\") )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different values above! When will the speaker favor non-literal utterances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the pragmatic listener doesn't know what the QUD is and so jointly reasons abut this and the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this listener interpret the uttered price \"10,000\"? On the one hand this is a very unlikely price *a priori*, on the other if it were true it would come with strong arousal. Altogether this becomes a plausible *hyperbolic* utterence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pragmatic Halo\n",
    "\n",
    "\"It cost fifty dollars\" is often interpretted as costing *around* 50 -- plausibly 51; yet \"it cost fiftyone dollars\" is interpretted as 51 and definitely not 50. This assymetric imprecision is often called the pragmatic halo or pragmatic slack.\n",
    "\n",
    "We can extend the hyperole model to capture this additional non-literal use of numbers by including QUD functions that collapse nearby numbers and assuming that round numbers are slightly more likely (because they are less difficult to utter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A helper to round a number to the nearest ten:\n",
    "def approx(x, b=None):\n",
    "    if b is None:\n",
    "        b = 10.\n",
    "    div = float(x)/b\n",
    "    rounded = int(div) + 1 if div - float(int(div)) >= 0.5 else int(div)\n",
    "    return int(b) * rounded\n",
    "\n",
    "#The QUD functions we consider:\n",
    "qud_fns = {\n",
    "    \"price\": lambda state: State(price=state.price, arousal=None),\n",
    "    \"arousal\": lambda state: State(price=None, arousal=state.arousal),\n",
    "    \"priceArousal\": lambda state: State(price=state.price, arousal=state.arousal),\n",
    "    \"approxPrice\": lambda state: State(price=approx(state.price), arousal=None),\n",
    "    \"approxPriceArousal\": lambda state: State(price=approx(state.price), arousal=state.arousal),\n",
    "}\n",
    "\n",
    "def qud_prior():\n",
    "    values = list(qud_fns.keys())\n",
    "    ix = pyro.sample(\"qud\", dist.Categorical(probs=torch.ones(len(values)) / len(values)))\n",
    "    return values[ix]\n",
    "\n",
    "def utterance_cost(numberUtt):\n",
    "    preciseNumberCost = 10.\n",
    "    return 0. if approx(numberUtt) == numberUtt else preciseNumberCost\n",
    "\n",
    "def utterance_prior():\n",
    "    utterances = [50, 51, 500, 501, 1000, 1001, 5000, 5001, 10000, 10001]\n",
    "    utteranceLogits = -torch.tensor(list(map(utterance_cost, utterances)),\n",
    "                                    dtype=torch.float64)\n",
    "    ix = pyro.sample(\"utterance\", dist.Categorical(logits=utteranceLogits))\n",
    "    return utterances[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSA speaker and listener definitions are unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Marginal\n",
    "def literal_listener(utterance):\n",
    "    state=state_prior()\n",
    "    factor(\"literal_meaning\", 0. if meaning(utterance, state.price) else -999999.)\n",
    "    return state\n",
    "\n",
    "@Marginal\n",
    "def speaker(state, qud):\n",
    "    alpha = 1.\n",
    "    qudValue = qud_fns[qud](state)\n",
    "    with poutine.scale(scale=torch.tensor(alpha)):\n",
    "        utterance = utterance_prior()\n",
    "        literal_marginal = literal_listener(utterance)\n",
    "        projected_literal = project(literal_marginal, qud)\n",
    "        pyro.sample(\"listener\", projected_literal, obs=qudValue)\n",
    "    return utterance\n",
    "\n",
    "@Marginal\n",
    "def pragmatic_listener(utterance):\n",
    "    state = state_prior()\n",
    "    qud = qud_prior()\n",
    "    speaker_marginal = speaker(state, qud)\n",
    "    pyro.sample(\"speaker\", speaker_marginal, obs=utterance)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's see if we get the desired assymetric slack (we're only interested in the interpretted price here, so we marginalize out the arousal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Marginal\n",
    "def pragmatic_listener_price_marginal(utterance):\n",
    "    return pyro.sample(\"pm\", pragmatic_listener(utterance)).price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Irony and More Complex Affect\n",
    "\n",
    "In the above hyperbole model we assumed a very simple model of affect: a single dimension with two values (high and low arousal). Actual affect is best represented as a two-dimensional space corresponding to valence and arousal. Kao and Goodman (2015) showed that extending the affect space to these two dimensions immediately introduces a new usage of numbers: verbal irony in which an utterance corresponding to a high-arousal positive valence state is used to convey a high-arousal but negative valence (or vice versa). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
